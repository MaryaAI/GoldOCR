{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61784d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pytesseract Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff892e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26c78b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Specify path to the Tesseract binary\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'<path_to_your_tesseract_executable>'\n",
    "\n",
    "def extract_arabic_text_with_bounding_boxes(image_path, output_file_path):\n",
    "    # Open the image\n",
    "    img = Image.open(image_path)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # Use Tesseract to detect text and bounding boxes\n",
    "    data = pytesseract.image_to_data(img, lang='eng', output_type=pytesseract.Output.DICT)\n",
    "    \n",
    "    # Open the output file\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "        # Filter out empty text and draw bounding boxes\n",
    "        for i in range(len(data['text'])):\n",
    "            if int(data['conf'][i]) > 60:  # Confidence threshold\n",
    "                (x, y, w, h) = (data['left'][i], data['top'][i], data['width'][i], data['height'][i])\n",
    "                draw.rectangle((x, y, x + w, y + h), outline='red')\n",
    "                detected_text = f\"Detected text: {data['text'][i]} (Confidence: {data['conf'][i]}%)\"\n",
    "                file.write(detected_text + '\\n')\n",
    "\n",
    "    # Display or save the image with bounding boxes\n",
    "    img.show()\n",
    "    img.save(r\"C:\\Users\\ASUS\\Desktop\\OCR\\output.jpg\")# to save the image\n",
    "\n",
    "# Example usage\n",
    "image_path = r\"C:\\Users\\ASUS\\Desktop\\OCR\\s1.jpg\"\n",
    "output_file_path = r\"C:\\Users\\ASUS\\Desktop\\OCR\\output.txt\"  # Define the path to your output file\n",
    "extract_arabic_text_with_bounding_boxes(image_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfdc8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Configure pytesseract path to where Tesseract is installed on your system\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'<full_path_to_your_tesseract_executable>'\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    \"\"\"\n",
    "    Extract text from the given image using OCR.\n",
    "    :param image_path: Path to the image file.\n",
    "    :return: Extracted text as a string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the image\n",
    "        img = Image.open(image_path)\n",
    "        \n",
    "        # Use Tesseract to do OCR on the image\n",
    "        text = pytesseract.image_to_string(img)\n",
    "        \n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Example usage\n",
    "image_path = r\"C:\\Users\\ASUS\\Desktop\\OCR\\s2.jpg\"\n",
    "extracted_text = extract_text_from_image(image_path)\n",
    "print(\"Extracted Text:\\n\", extracted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962c60c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "def preprocess_image(img):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply thresholding to extract text regions\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Perform morphological operations to enhance text regions\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    \n",
    "    # Return the preprocessed image\n",
    "    return morph\n",
    "\n",
    "def extract_text(img):\n",
    "    # Use Tesseract OCR to extract text from the image\n",
    "    extracted_text = pytesseract.image_to_string(img)\n",
    "    return extracted_text\n",
    "\n",
    "def main():\n",
    "    # Load the image of the gold\n",
    "    image_path = r\"C:\\Users\\ASUS\\Desktop\\OCR\\s2.jpg\"\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Preprocess the image\n",
    "    preprocessed_img = preprocess_image(img)\n",
    "    \n",
    "    # Extract text from the preprocessed image\n",
    "    extracted_text = extract_text(preprocessed_img)\n",
    "    \n",
    "    # Print the extracted text\n",
    "    print(\"Extracted Text:\")\n",
    "    print(extracted_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aedf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "\n",
    "# Load image\n",
    "image_path = r\"C:\\Users\\ASUS\\Desktop\\OCR\\s2.jpg\" # Replace with the path to your image\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Grayscale conversion\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gaussian blur for noise reduction\n",
    "blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "\n",
    "# Thresholding to binarize the image\n",
    "_, binary_image = cv2.threshold(blurred_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "# Perform dilation and erosion for noise removal\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "processed_image = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Perform text extraction using pytesseract\n",
    "extracted_text = pytesseract.image_to_string(processed_image, lang='ara')  # Assuming Arabic language\n",
    "print(\"Extracted Text:\")\n",
    "print(extracted_text)\n",
    "\n",
    "# Save preprocessed image\n",
    "cv2.imwrite('preprocessed_gold_lashq_image.jpg', processed_image)\n",
    "\n",
    "# Display preprocessed image\n",
    "cv2.imshow('Preprocessed Image', processed_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cb4840",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Perform adaptive thresholding\n",
    "    threshold = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "    return threshold\n",
    "\n",
    "def extract_text(image):\n",
    "    # Preprocess image\n",
    "    preprocessed_image = preprocess_image(image)\n",
    "    \n",
    "    # Extract text using Tesseract OCR\n",
    "    extracted_text = pytesseract.image_to_string(preprocessed_image, lang='eng')\n",
    "    \n",
    "    return extracted_text\n",
    "\n",
    "# Load image\n",
    "image_path = r\"C:\\Users\\ASUS\\Desktop\\OCR\\s2.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Extract text\n",
    "extracted_text = extract_text(image)\n",
    "print(\"Extracted Text:\", extracted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba2c1e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def preprocess_gold_image(image):\n",
    "  \"\"\"\n",
    "  Preprocesses an image of gold for OCR.\n",
    "\n",
    "  Args:\n",
    "    image: The input image as a NumPy array.\n",
    "\n",
    "  Returns:\n",
    "    The preprocessed image as a NumPy array.\n",
    "  \"\"\"\n",
    "\n",
    "  # Convert to grayscale\n",
    "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  # Apply median filter for noise reduction\n",
    "  denoised = cv2.medianBlur(gray, 5)\n",
    "\n",
    "  # Apply adaptive thresholding for contrast enhancement\n",
    "  thresh = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "  # Perform morphological closing for shadow removal\n",
    "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "  closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "  # Improve local contrast (optional)\n",
    "  clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "  enhanced = clahe.apply(closed)\n",
    "\n",
    "  return enhanced\n",
    "\n",
    "# # Example usage\n",
    "# image = cv2.imread(r\"C:\\Users\\ASUS\\Desktop\\OCR\\s2.jpg\")\n",
    "# preprocessed = preprocess_gold_image(image)\n",
    "\n",
    "# # Display the preprocessed image\n",
    "# cv2.imshow(\"Preprocessed Image\", preprocessed)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19a775dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text: Ty me; SN\n",
      "SUISSE)\n",
      "‘GEO a: }\n",
      "\n",
      "_ 29,0\n",
      "‘g2rg92f,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##best one\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Prerequisite: Install pytesseract and ensure Tesseract-OCR is installed and accessible\n",
    "#pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Replace with your Tesseract-OCR path\n",
    "\n",
    "def preprocess_and_read_text(image_path):\n",
    "    \"\"\"\n",
    "    Preprocesses an image of gold and extracts text using pytesseract.\n",
    "\n",
    "    Args:\n",
    "        image_path: The path to the input image.\n",
    "\n",
    "    Returns:\n",
    "        The extracted text.\n",
    "    \"\"\"\n",
    "\n",
    "    image = cv2.imread(r\"C:\\Users\\ASUS\\Desktop\\OCR\\s2.jpg\")\n",
    "    preprocessed = preprocess_gold_image(image)  # Apply preprocessing steps\n",
    "\n",
    "    # Save preprocessed image\n",
    "    cv2.imwrite('preprocessed_gold_image.jpg', preprocessed)\n",
    "    \n",
    "    # Use Tesseract to detect text and bounding boxes\n",
    "    #data = pytesseract.image_to_data(preprocessed, lang='eng', output_type=pytesseract.Output.DICT)\n",
    "    \n",
    "    #text = pytesseract.image_to_string(preprocessed, config='--psm 6')  # Assuming single uniform block of text\n",
    "    # Extract text with configuration options\n",
    "    text = pytesseract.image_to_string(preprocessed, config='--psm 6 tessedit_char_whitelist=0123456789')\n",
    "\n",
    "    \n",
    "#     # Extract data (optional)\n",
    "    \n",
    "#     data = pytesseract.image_to_data(preprocessed,lang='eng', output_type=pytesseract.Output.DICT)\n",
    "#     n_boxes = len(data['level'])\n",
    "#     for i in range(n_boxes):\n",
    "#         (x, y, w, h) = (data['left'][i], data['top'][i], data['width'][i], data['height'][i])\n",
    "#         cv2.rectangle(preprocessed, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "#     cv2.imshow('img', preprocessed)\n",
    "#     cv2.waitKey(0)\n",
    "#     print(data)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text = preprocess_and_read_text(r\"C:\\Users\\ASUS\\Desktop\\OCR\\s2.jpg\")\n",
    "print(\"Extracted text:\", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d415364",
   "metadata": {},
   "outputs": [],
   "source": [
    "    img=\n",
    "    text = pytesseract.image_to_string(preprocessed, config='--psm 6')  # Assuming single uniform block of text\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d734d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_and_extract(image_path):\n",
    "    \"\"\"\n",
    "    Preprocesses an image, detects text bounding boxes, and extracts text using pytesseract.\n",
    "\n",
    "    Args:\n",
    "        image_path: The path to the input image.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries containing extracted text and bounding box coordinates.\n",
    "    \"\"\"\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Preprocessing steps (adjust based on your image characteristics)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    denoised = cv2.medianBlur(gray, 5)\n",
    "    thresh = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # Detect text regions using Tesseract\n",
    "    boxes = pytesseract.image_to_boxes(thresh)\n",
    "\n",
    "    # Extract text and bounding boxes\n",
    "    extracted_data = []\n",
    "    for box in boxes.splitlines():\n",
    "        try:\n",
    "            x, y, w, h, text = box.split(' ')\n",
    "            extracted_data.append({\n",
    "                \"text\": text,\n",
    "                \"x\": int(x),\n",
    "                \"y\": int(y),\n",
    "                \"w\": int(w),\n",
    "                \"h\": int(h)\n",
    "           })\n",
    "        except ValueError:\n",
    "        # Handle cases where there are not exactly 5 values\n",
    "            pass\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "# Example usage\n",
    "extracted_data = preprocess_and_extract(r\"C:\\Users\\ASUS\\Desktop\\OCR\\s2.jpg\")\n",
    "for data in extracted_data:\n",
    "    print(\"Text:\", data[\"text\"])\n",
    "    print(\"Bounding box:\", data[\"x\"], data[\"y\"], data[\"w\"], data[\"h\"])\n",
    "\n",
    "    # Optionally draw bounding boxes on the image\n",
    "    cv2.rectangle(extracted_data, (data[\"x\"], data[\"y\"]), (data[\"x\"] + data[\"w\"], data[\"y\"] + data[\"h\"]), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Image with Bounding Boxes\", extracted_data)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd10204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f4c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Prerequisite: Install pytesseract and ensure Tesseract-OCR is installed and accessible\n",
    "#pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Replace with your Tesseract-OCR path\n",
    "\n",
    "\n",
    "def preprocess_and_extract(image_path):\n",
    "    \"\"\"\n",
    "    Preprocesses an image, detects text bounding boxes, and extracts text using pytesseract.\n",
    "\n",
    "    Args:\n",
    "        image_path: The path to the input image.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries containing extracted text and bounding box coordinates.\n",
    "    \"\"\"\n",
    "\n",
    "    image = cv2.imread(r\"C:\\Users\\ASUS\\Desktop\\OCR\\s2.jpg\")\n",
    "\n",
    "    # Preprocessing steps (adjust based on your image characteristics)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    denoised = cv2.medianBlur(gray, 5)\n",
    "    thresh = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # Detect text regions using Tesseract\n",
    "    boxes = pytesseract.image_to_boxes(thresh)\n",
    "\n",
    "    # Extract text and bounding boxes\n",
    "    extracted_data = []\n",
    "    for box in boxes.splitlines():\n",
    "        try:\n",
    "            # Handle potential empty values or extra spaces\n",
    "            clean_box = box.strip().replace('\\n', '')\n",
    "            x, y, w, h, text = clean_box.split(' ')\n",
    "            extracted_data.append({\n",
    "                \"text\": text,\n",
    "                \"x\": int(x),\n",
    "                \"y\": int(y),\n",
    "                \"w\": int(w),\n",
    "                \"h\": int(h)\n",
    "            })\n",
    "        except ValueError:\n",
    "            # Handle cases where there are not exactly 5 values\n",
    "            pass\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "# Example usage\n",
    "extracted_data = preprocess_and_extract(r\"C:\\Users\\ASUS\\Desktop\\OCR\\s2.jpg\")\n",
    "\n",
    "# Read the image within this block\n",
    "image = cv2.imread(r\"C:\\Users\\ASUS\\Desktop\\OCR\\s2.jpg\") \n",
    "\n",
    "for data in extracted_data:\n",
    "    print(\"Text:\", data[\"text\"])\n",
    "    print(\"Bounding box:\", data[\"x\"], data[\"y\"], data[\"w\"], data[\"h\"])\n",
    "\n",
    "    # Optionally draw bounding boxes on the image\n",
    "    cv2.rectangle(image, (data[\"x\"], data[\"y\"]), (data[\"x\"] + data[\"w\"], data[\"y\"] + data[\"h\"]), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Image with Bounding Boxes\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425248e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Load the gold image\n",
    "image_path = r\"C:\\Users\\ASUS\\Desktop\\OCR\\s2.jpg\"\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Preprocessing: Shadow removal, binarization, and deskewing\n",
    "def preprocess_image(image):\n",
    "    # Your shadow removal and other preprocessing steps here\n",
    "    # ...\n",
    "\n",
    "    # Example: Convert to grayscale and apply thresholding\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_image = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    return binary_image\n",
    "\n",
    "preprocessed_image = preprocess_image(img)\n",
    "\n",
    "# Detect bounding boxes using pytesseract\n",
    "detection_config = \"--psm 6\"  # Assume a single uniform block of text\n",
    "boxes = pytesseract.image_to_boxes(preprocessed_image, config=detection_config).splitlines()\n",
    "\n",
    "# Extract text and draw bounding boxes\n",
    "for box in boxes:\n",
    "    _, x, y, w, h, _ = map(int, box.split())\n",
    "    cv2.rectangle(img, (x, y), (w, h), (0, 255, 0), 2)\n",
    "\n",
    "    # Extract text within the bounding box\n",
    "    cropped_text = pytesseract.image_to_string(preprocessed_image[y:h, x:w], config=detection_config)\n",
    "    print(f\"Text in bounding box: {cropped_text}\")\n",
    "\n",
    "# Display the image with bounding boxes\n",
    "cv2.imshow(\"Gold Image with Bounding Boxes\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f3ba932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUISSE\n",
      "Boo :\n",
      "y\n",
      "222222 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread(r\"C:\\Users\\ASUS\\Desktop\\OCR\\s2.jpg\")\n",
    "\n",
    "# Preprocess the image (optional)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "\n",
    "\n",
    "# Extract text with configuration options\n",
    "text = pytesseract.image_to_string(thresh, config='--psm 6 tessedit_char_whitelist=0123456789')\n",
    "\n",
    "# Print the extracted numbers\n",
    "print(text)\n",
    "\n",
    "# Optional: Validate extracted numbers using regular expressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0474dc21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
